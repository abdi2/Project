{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation,Flatten,MaxPool2D,Conv2D,BatchNormalization,Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.simplefilter(action='ignore',category = FutureWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the code below imports and processes the images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n",
    "                                   horizontal_flip=True,\n",
    "        vertical_flip=True,rescale = 1./255,\n",
    "                                   validation_split = 0.2).flow_from_directory(directory = 'Alzheimer_s Dataset/train',\n",
    "                                                  target_size = (176,208),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  batch_size = 128)\n",
    "\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n",
    "                                   validation_split = 0.2).flow_from_directory(directory = 'Alzheimer_s Dataset/train',\n",
    "                                                  target_size = (176,208),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  batch_size = 128)\n",
    "\n",
    "test_batches  = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory = 'Alzheimer_s Dataset/test',\n",
    "                                                  target_size = (176,208),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  batch_size = 128)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##shows you the one hot encoded images and their labels\n",
    "imgs,labels = next(test_batches)\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(np.uint8(img))\n",
    "\n",
    "plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16 = tf.keras.applications.VGG16( include_top=False, weights='imagenet', input_shape=(224,224,3),\n",
    "    pooling=\"avg\", classes=4\n",
    "   \n",
    ")\n",
    "# we are gonna disregard the pretrained model with the weights already made \n",
    "for layer in VGG16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout of VGG16\n",
    "VGG16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we modify the softmax layer to show 4 possible outcomes\n",
    "model=Sequential()\n",
    "model.add(VGG16)\n",
    "\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "#the learning rate, the loss and accuracy metric\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#what the model will look like\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path we will save the best \n",
    "filepath = './best_weights.hdf5'\n",
    "\n",
    "earlystopping = EarlyStopping(monitor = 'val_acc', \n",
    "                              mode = 'max' , \n",
    "                              patience = 15,\n",
    "                              verbose = 1)\n",
    "\n",
    "checkpoint    = ModelCheckpoint(filepath, \n",
    "                                monitor = 'val_acc', \n",
    "                                mode='max', \n",
    "                                save_best_only=True, \n",
    "                                verbose = 1)\n",
    "\n",
    "\n",
    "callback_list = [earlystopping, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will train our model\n",
    "model_history=model.fit(train_batches,\n",
    "                        validation_data=valid_batches,\n",
    "                        epochs = 1,\n",
    "                        callbacks = callback_list,\n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have a trained model we can test its accuracy on new images it hasnt seen before \n",
    "test_imgs, test_labels =next(test_batches)\n",
    "#in order to get a more accurate view of what is happening in our model\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluates the model on a test batch\n",
    "scores = model.evaluate(test_batches)\n",
    "print(\"Accuracy = \", scores[1])\n",
    "print(\"Precision = \", scores[2])\n",
    "print(\"Recall = \", scores[3])\n",
    "print(\"AUC = \", scores[4])\n",
    "print(\"F1_score = \", scores[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this creates a confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "        normalize=False,\n",
    "        title='Confusion matrix',\n",
    "        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred=predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['Mild','Moderate',\"None\",\"VeryMild\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
